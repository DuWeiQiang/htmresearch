#
# Parameters used in the final ICML paper
#

[DEFAULT]
# Keep final results in a separate location
path = results_final

experiment = grid
repetitions = 1
seed = 42
datadir = data
lr_scheduler = StepLR
lr_scheduler_params = "{'step_size': 1, 'gamma':%(learning_rate_factor)s}"
validation = 1.0
no_cuda = False
batches_in_epoch = 100000
log_interval = 1000
test_batch_size = 1000
create_plots = False
count_nonzeros = True
test_noise_every_epoch = True

#
# Noise Experiments. Figures X,Y,Z. Tables A,B,C
# Compare accuracy over noise using fully connected neural networks (Dense) and
# sparse neural networks (Sparse) with and without dropout
#
[DropoutDense]
batch_size = 16
iterations = 10

n = 500
k = 500
k_inference_factor = 1.0

weight_sparsity = 1.0
min_dutycycle = 0.0
min_weight = 0.0

boost_strength = 0.0
boost_strength_factor = 1.0

optimizer = SGD
learning_rate = 0.04
learning_rate_factor = 0.5
momentum = 0.5

dropout=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]

use_batch_norm = False

use_cnn = False
c1_k = 0
c1_out_channels = 0

[DropoutSparse]
batch_size = 4
iterations = 10

n = 500
k = 50
k_inference_factor = 1.5

weight_sparsity = 0.4
min_dutycycle = 0.0
min_weight = 0.0

boost_strength = 1.0
boost_strength_factor = 0.9

optimizer = SGD
learning_rate = 0.04
learning_rate_factor = 0.5
momentum = 0.5

dropout=[0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]

use_batch_norm = False

use_cnn = False
c1_k = 0
c1_out_channels = 0

;[DropoutDenseCNN]
;[DropoutSparseCNN]

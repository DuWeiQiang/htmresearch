[DEFAULT]

batch_size = 64         # mini batch size
test_batch_size = 1000
learning_rate = 0.02
momentum = 0.25
boost_strength = 2.0
seed = 42
n = 2000
k = 200
weight_sparsity = 0.50

repetitions = 1
iterations = 20         # Number of training epochs
no_cuda = False         # If True, disables CUDA training
log_interval = 1000     # how many minibatches to wait before logging
                        # training status

path = results
datadir = "projects/sdr_paper/pytorch_experiments/data"


;[experiment1]
;n = 1000
;k = [200, 100]
;boost_strength = [0.0, 1.0, 2.0, 3.0]
;learning_rate = [0.02, 0.04, 0.06]
;momentum = [0.5, 0.25]
;
;[experiment2]
;n = 2000
;k = [300, 200, 100]
;boost_strength = [0.0, 0.5, 1.0]
;learning_rate = [0.02]
;momentum = [0.5, 0.25]

; Took too long!!
;[experiment2Stopped]
;weight_sparsity = 0.5
;no_cuda = False
;learning_rate = [0.02, 0.04, 0.06]
;repetitions = 1
;test_batch_size = 1000
;batch_size = 64
;n = 2000
;seed = 42
;log_interval = 1000
;iterations = 12
;path = results
;boost_strength = [0.0, 0.5, 1.0, 1.5, 2.0]
;k = [300, 200, 100]
;momentum = [0.5, 0.25, 0.0]

;[experiment3]
;n = 2000
;k = [400, 200, 100]
;boost_strength = [0.0, 0.5]
;learning_rate = [0.02]

;Testing the effect of weight sparsity
;[experiment4]
;n = 2000
;k = [200, 100]
;boost_strength = [0.0, 0.5, 1.0, 1.5]
;weight_sparsity = [0.80, 0.5, 0.35, 0.25]

;Test effect of higher n
;[experimentTemp]
;n = 4000
;k = [400, 200]
;boost_strength = [0.0, 0.5, 1.0, 1.5]
;weight_sparsity = [0.80, 0.5, 0.35, 0.25]

;Fixed boosting to start immediately and check impact of boost
;Stopped
;[experiment6]
;n = 1000
;k = [200, 100]
;boost_strength = [0.0, 0.5, 1.0, 1.5, 2.0]
;learning_rate = [0.04]
;momentum = [0.5, 0.25]
;weight_sparsity = [0.5, 0.35]

;Fixed boosting to start immediately and check impact of boost
;Fewer iterations
;[experiment7]
;n = 1000
;k = [200, 100]
;boost_strength = [0.0, 0.5, 1.0, 1.5, 2.0]
;learning_rate = [0.04]
;momentum = [0.25]
;weight_sparsity = [0.5, 0.35]
;iterations = 10

;As above but with larger numbers
;[experiment8]
;n = 2000
;k = [200, 100]
;boost_strength = [0.0, 1.0, 1.5, 2.0]
;learning_rate = [0.04]
;momentum = [0.25]
;weight_sparsity = [0.45, 0.35, 0.25]
;iterations = 20

;Copy of above for testing larger instance
[experiment9]
n = 2000
k = [200, 100]
boost_strength = [0.0, 1.0, 1.5, 2.0]
learning_rate = [0.04]
momentum = [0.25]
weight_sparsity = [0.45, 0.35, 0.25]
iterations = 20

;[experimentQuick]
;n = 100
;k = [20, 10]
;iterations = 2

